{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorio de Regresión Lineal\n",
    "\n",
    "Los atributos que relacionan los datos con nuestra variable objetivo pueden estar relacionados linealmente. Por ejemplo, ha sido utilizada en la predicción de \n",
    "\n",
    "* Indicadores y KPIs en empresas. \n",
    "* Indicadores macro-económicos. \n",
    "* Gestión de stock en la industria del retail.\n",
    "* Entre muchos otros ejemplos.\n",
    "\n",
    "\n",
    "El método de regresión lineal justamente tiene como objetivo encontrar la relación lineal que existe entre los datos X y la variable objetivo Y. Esta puede escribirse matemáticamente de la siguiente forma:\n",
    "    \n",
    "   $$Y=\\alpha X + \\beta$$\n",
    "\n",
    "donde es necesario encontrar (o aprender a partir de los datos) cuales son los (vectores de) coeficientes $\\alpha$ y (el escalar) $\\beta$ que minimizan el error. Dicho de otra forma, el objetivo de un modelo de regresión es tratar de explicar la relación que existe entre una variable dependiente $Y$ que queremos predecir, un conjunto de variables independientes (variables explicativas) $X_1,..., X_n$.\n",
    "\n",
    "¿Cómo medimos el error que queremos minimizar?\n",
    "Un estándar es usar el error cuadrático medio: \n",
    "\n",
    "$$error=\\sum_{i=1}^n (Y_r(X_i) - Y_p(X_i))^2$$\n",
    "\n",
    "donde $Y_r(X_i)$ es el valor de la variable objetivo para los datos del conjunto de datos de prueba, y $Y_p(X_i)$ es el valor predicho para cada $X_i$ en el conjunto de datos de las variables explicativas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iniciamos importando las liberías que necesitaremos.\n",
    "\n",
    "# Librería para el manejo de DataFrames\n",
    "import pandas as pd   \n",
    "\n",
    "# libería de análisis numérico de mucha utilidad.\n",
    "import numpy as np   \n",
    "\n",
    "# librería de visualización\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "# De la librería de aprendizaje automático sklearn, \n",
    "#importamos el modelo de regresión lineal\n",
    "from sklearn import linear_model \n",
    "\n",
    "# Finalmente importamos la función train_test_split, que como indíca su nombre\n",
    "# separa los datos de entrada en un conjunto para entrenamiento, y otro para pruebas.\n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Objetivo:\n",
    "predecir el precio de una casa en función de alguna de las variables independientes o atributos que podamos tener. En este caso, utilizaremos un conjunto de datos disponible en la misma librería sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cargamos la sublibrería de conjuntos de datos:\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y cargamos los datos a utilizar en la variable boston.\n",
    "boston=load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# podemos mirar de que tipo son los datos en dicha variable:\n",
    "type(boston)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
      "        4.9800e+00],\n",
      "       [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
      "        9.1400e+00],\n",
      "       [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
      "        4.0300e+00],\n",
      "       ...,\n",
      "       [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
      "        5.6400e+00],\n",
      "       [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
      "        6.4800e+00],\n",
      "       [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
      "        7.8800e+00]]), 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
      "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
      "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
      "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
      "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
      "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
      "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
      "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
      "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
      "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
      "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
      "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
      "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
      "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
      "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
      "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
      "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
      "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
      "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
      "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
      "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
      "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
      "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
      "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
      "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
      "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
      "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
      "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
      "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
      "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
      "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
      "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
      "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
      "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
      "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
      "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
      "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
      "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
      "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
      "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
      "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
      "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
      "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
      "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
      "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
      "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]), 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
      "       'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'), 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\", 'filename': '/Users/aa/opt/anaconda3/lib/python3.7/site-packages/sklearn/datasets/data/boston_house_prices.csv'}\n"
     ]
    }
   ],
   "source": [
    "print(boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos un número total de atributos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(boston.feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para trabajar con estructuras mas agradables, utilizamos la librería\n",
    "# pandas para construir los dataframes correspondientes a los datos y variable \n",
    "# objetivo dependiente de estos.\n",
    "df_x=pd.DataFrame(boston.data,columns=boston.feature_names)\n",
    "df_y=pd.DataFrame(boston.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT  \n",
       "count  506.000000  \n",
       "mean    12.653063  \n",
       "std      7.141062  \n",
       "min      1.730000  \n",
       "25%      6.950000  \n",
       "50%     11.360000  \n",
       "75%     16.955000  \n",
       "max     37.970000  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Un método muy util de estas estructuras es el método describe() que da un\n",
    "# resumen de métricas de mayor relevancia.\n",
    "df_x.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dicho esto, procedemos a inicializar nuestro modelo de regresión lineal. Esto lo hacemos invocandolo desde la librería scikit-learn a través de:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg=linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos los datos que utilizaremos para el entrenamiento y los datos que utilizaremos luego para probar la eficiencia de nuestro modelo usando la función train_test_split de scikit-learn. Separaremos los datos dejando el 20% como datos de prueba y el 80% como datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test,y_train,y_test=train_test_split(df_x,df_y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez separados los datos, usamos x_train y y_train para entrenar/ajustar el modelo. Esto lo hacemos con el método fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "los coeficientes del modelo son \n",
      "[-1.05860348e-01  5.11363454e-02  4.52199105e-02  2.35150639e+00\n",
      " -1.84767939e+01  3.45541632e+00  7.12270235e-03 -1.51143052e+00\n",
      "  3.20541767e-01 -1.27596384e-02 -9.68439185e-01  9.05004344e-03\n",
      " -5.89510835e-01]\n"
     ]
    }
   ],
   "source": [
    "print('los coeficientes del modelo son \\n'+str(reg.coef_[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y el escalar $\beta$ es 39.589958451994875\n"
     ]
    }
   ],
   "source": [
    "print('y el escalar $\\beta$ es '+str(reg.intercept_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recordar que eran 13 atributos, de manera que debemos tener el mismo número de coeficientes. En efecto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reg.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos ahora las predicciones sobre el conjunto de datos de prueba, usando el método predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prediction=reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente ver que tan buena es nuestra predicción versus los valores provenientes de los datos. Si la predicción es buena, al graficar la predicción versus los datos que debían predecirse, deberían desplegarse en una linea (función identidad y=x). Entre mas cercana esté la nube de puntos a la función identidad, mas precisa será la predicción.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test=np.array(y_test)\n",
    "y_prediction=np.array(y_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.plot(y_prediction,y_test, '.')\n",
    "plt.plot(range(50),range(50))\n",
    "plt.xlabel('objetivo:predicción')\n",
    "plt.ylabel('objetivo:test')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observar que los datos están alrededor de la recta dada por la función identidad. Sin embargo, sabemos que el problema de asignarle el costo a una casa es altamente complejo, no-lineal, y depende de factores algunas veces volátiles, como la economía del país, segregación social, modificaciones internas, y no solo de los aspectos mas visibles como tamaño, antigüedad y número de habitaciones. Finalmente, medimos el error cuadrático medio encontrado por el algoritmo de regresión lineal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.259987818768664\n"
     ]
    }
   ],
   "source": [
    "print(mean_squared_error(y_prediction, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pregunta abierta\n",
    "¿Es posible mejorar este valor de alguna forma?, ¿que método utilizaría?. \n",
    "\n",
    "Investigue sobre redes neuronales tipo perceptrón. \n",
    "\n",
    "Proyecto a futuro: ¿Que valores alcanzaría un fit con una red neuronal multicapa con neuronas tipo perceptron?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
